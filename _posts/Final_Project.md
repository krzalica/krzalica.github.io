---
layout: post
title: Final_Project
---
Date: 01/07/2020
Today I began to seriously search for a large dataset to analyze. While I struggled to find the correct keywords for the search at first, I soon managed to find a dataset that perfectly fit my needs and was even compiled with my specific purpose in mind: https://www.kaggle.com/mfekadu/darpa-timit-acousticphonetic-continuous-speech. The ReadMe was extremely intriguing to read, as it joined both linguistics of American English dialects and discussed the several test/train splits the authors suggested. The dataset also contains a huge amount of data, which will afford me the opportunity to showcase my ability to clean and synthesize datasets. I also found a paper describing the analysis of audio using python, though I do not know how useful that will be until I dig into the dataset and its contents tomorrow.

Date: 01/08/2020
Today I began by reading in the dataset and exploring it to get my bearings as to how the researchers organized their information. I quickly realized that the dataset was mostly just for organization, with all of the audio data stored in the folders downloaded alongside the dataset. The audio data was in the waveform audio format, making it clear that I'd need to use pyAudioAnalysis, which I'd discovered yesterday. As a result, I read the general information offered by the developers before delving into feature extraction, which I will need to be able to classify the recordings. The sheer number of potential features overwhelmed me almost immediately, and so I took a step back, deciding instead to specifically research audio analysis for machine learning. Keeping in mind the massive amount of audio data I am working with, I decided to use Mel Frequency Cepstral Coefficients (MFCCs) as my feature of focus, as they, much like SVD, contain the most essential information from the audio. Tomorrow I plan to work on analyzing only one recording with pyAudioAnalysis, so that I can feel confident in my coding before applying it to the rest of the training set. I will also continue to consider which models to utilize in relating the audio with the text, as well as what I wish to do with this model beyond simply creating a good regression for it (I'm hoping to incorporate some Natural Language Processing).